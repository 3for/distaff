## Proof generation

To generate a STARK proof, we use `prove()` function from the [prover](prover.rs) module. The function takes the following parameters:

* **trace**: `&TraceTable` - an execution trace resulting from executing a program. The trace table is built by the [processor](../processor) module.
* **inputs**: `&[64]`
* **outputs**: `&[u64]`
* **options**: `&ProofOptions`

### Domains
Proof generation involves (among other things) interpolating and evaluating a bunch of polynomials. These polynomials are interpolated and evaluated over various domains, and it is useful to understand what these domains are.

In general, domains for STARKs consist of successive powers of primitive roots of unity. Specifically:

<p align="center">
1, ω, ω<sup>2</sup>, ω<sup>3</sup>, . . . , ω<sup>n-1</sup>
</p>

where *ω* is the *n*-th primitive root of unity. You can also think of *n* as the size of the domain and of *ω* as the domain's generator.

There are 3 domains with which we'll be working:

1. Domain of the trace table or *D<sub>trace</sub>* generated by *ω<sub>trace</sub>*. The size of this domain is equal to the length of the execution trace, and it is the smallest domain out of the three.
2. Constraint evaluation domain or *D<sub>ev</sub>* generated by *ω<sub>ev</sub>*. This domain is bigger than the trace domain by a factor of `MAX_CONSTRAINT_DEGREE`. Currently, `MAX_CONSTRAINT_DEGREE` is 8, so the constraint evaluation domain is 8 times bigger than the trace domain.
3. Low degree extension domain or *D<sub>lde</sub>* generated by *ω<sub>lde</sub>*. This domain is bigger than the trace domain by they `extension_factor` parameter. `extension_factor` must be at least 16 (but may be significantly bigger) - so, LDE domain is the biggest one of the three.

### 1. Extend execution trace

We can think of register traces in the execution trace table as evaluations of trace polynomials *T<sub>i</sub>(x)*. Thus, each row in the trace table can be written as:

<p align="center">
T<sub>0</sub>(ω<sup>i</sup><sub>trace</sub>), T<sub>1</sub>(ω<sup>i</sup><sub>trace</sub>), T<sub>2</sub>(ω<sup>i</sup><sub>trace</sub>), . . . T<sub>k</sub>(ω<sup>i</sup><sub>trace</sub>)
</p>

where, *k* is the number of registers, and *i* is the index of the row (same as the step of the computation).

To extend the trace table, we need to evaluate these polynomials over a larger domain. But since the trace table consists of polynomial evaluations, we first need to interpolate each register trace into a polynomial. We do this by running inverse FFT.

Then, trace polynomials are evaluated over *D<sub>lde</sub>* to generate the extended trace table (this is done by running regular FFT). Each row in the extended trace table can be written as:

<p align="center">
T<sub>0</sub>(ω<sup>i</sup><sub>lde</sub>), T<sub>1</sub>(ω<sup>i</sup><sub>lde</sub>), T<sub>2</sub>(ω<sup>i</sup><sub>lde</sub>), . . . T<sub>k</sub>(ω<sup>i</sup><sub>lde</sub>)
</p>

A couple of things to note:
1. The degree of trace polynomials is one less than trace length, or *deg(T<sub>i</sub>(x)) = |D<sub>trace</sub>| - 1*.
2. This step alone takes up almost 45% of proof generation time (in single-threaded execution).

### 2. Build trace Merkle tree

After the execution trace table has been extended, we build a Merkle tree from the extended register traces. Leaves in the resulting tree will have the following form:

<p align="center">
Leaf<sub>i</sub> = (T<sub>0</sub>(ω<sup>i</sup><sub>lde</sub>), T<sub>1</sub>(ω<sup>i</sup><sub>lde</sub>), T<sub>2</sub>(ω<sup>i</sup><sub>lde</sub>), . . . T<sub>k</sub>(ω<sup>i</sup><sub>lde</sub>))
</p>

This step takes up about 10% of proof generation time.

### 3. Evaluate constraints
The next step is to evaluate constraints. The actual constraint definitions are described [here](constraints). Our eventual goal is to combine all constraints into a single *constraint polynomial*. We do this by computing a random linear combination of all constraints like so:

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large C(x) = \sum_i (\k_{2i} \cdot C_i(x) %2B \k_{2i%2B1} \cdot C_i(x) \cdot x^{d_i})">
</p>

where:
* *x = ω<sup>j</sup><sub>ev</sub>* for all *j* in the constraint evaluation domain.
* *C<sub>0</sub> ... C<sub>i</sub>* are the individual constraint evaluation functions.
* *k<sub>0</sub> ... k<sub>2i+1</sub>* are the coefficients for the random linear combination. These coefficients are derived using PRNG seeded with the root of the trace Merkle tree we built in the previous step.
* *d<sub>0</sub> ... d<sub>i</sub>* are the adjustment degrees needed to guarantee that constraint degrees are enforced exactly. Adjustment degrees are calculated as: *d<sub>i</sub> = [target degree] - deg(C<sub>i</sub>(x))*.

However, in this step, we don't compute the full constraint polynomial. Instead, we compute linear combinations of constraint numerators only. In the next step, we'll divide these linear combinations by their respective denominators. This allows us to minimize the number of divisions (which are expensive) and also reduces the amount of RAM needed to hold all constraint evaluations. Since our constraints can have 3 possible denominators, we'll still need to keep track of 3 separate linear combinations but that's much better than keeping track of 30+ individual constraint evaluations.

The 3 combinations we need to keep track of are:

1. Combination of transition constraints. The denominator for this combination is *(x<sup>n</sup> - 1) / (x - ω<sub>trace</sub><sup>(n-1)</sup>)*.
2. Combination of boundary constraints at the first step. The denominator for this combination is *(x - 1)*.
3. Combination of boundary constraints at the last step. The denominator for this combination is *(x - ω<sub>trace</sub><sup>(n-1)</sup>)*.

Because the denominators above have different degrees, *target degrees* for the linear combination will be different. Specifically:
* Target degree for transition constraints will be *|D<sub>ev</sub>| - 1*.
* Target degree for boundary constraints will be *|D<sub>ev</sub>| - |D<sub>trace</sub>| + 1*

This way, when each linear combination is divided by its respective denominator, their degrees will align, and the degree for the full *constraint polynomial* will be:

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large deg(C(x)) = |D_{ev}| - |D_{trace}|">
</p>

For example, if our execution trace is 16 steps long:
* Constraint combination degree will be `16 * 8 - 1 = 127`.
* Boundary constraint combination degree will be `16 * 8 - 16 + 1 = 113`.
* Once the denominators are divided out, the final degree of the *constraint polynomial* will be `112`.

### 4. Convert constraint evaluations into a single polynomial
After constraints have been evaluated and combined into the 3 linear combinations, we do the following:
1. Interpolate each combination of constraint evaluation into a polynomial,
2. Divide out denominators from their respective polynomials,
3. Add the resulting polynomials together into the *constraint polynomial C(x)*.

### 5. Build Merkle tree from constraint polynomial evaluations
Once the *constraint polynomial* has been constructed, we evaluate it over the LDE domain and put the resulting values into a Merkle tree.

Since our values are 64 bits, but Merkle tree leaves are 256 bits, we put 4 consecutive evaluations into a single leaf like so:

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large Leaf_i=(C(x_{4*i}), C(x_{4*i %2B 1}), C(x_{4*i %2B 2}), C(x_{4*i %2B 3}))">
</p>

### 6. Build and evaluate deep composition polynomial
TODO

### 7. Compute FRI layers for the composition polynomial
TODO

### 8. Determine query positions
TODO

### 9. Build proof object
TODO

## Proof verification

### 1. Verify deep point evaluation
TODO

### 2. Verify proof of work and determine query positions
TODO

### 3. Verify trace and constraint Merkle proofs
TODO

### 4. Compute composition values
TODO

### 5. Verify low-degree proof
TODO