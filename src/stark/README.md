## Proof generation

To generate a STARK proof, we use `prove()` function from the [prover](prover.rs) module. The function takes the following parameters:

* **trace**: `&TraceTable` - an execution trace resulting from executing a program. The trace table is built by the [processor](../processor) module.
* **inputs**: `&[64]`
* **outputs**: `&[u64]`
* **options**: `&ProofOptions`

### Domains
Proof generation involves (among other things) interpolating and evaluating a bunch of polynomials. These polynomials are interpolated and evaluated over various domains, and it is useful to understand what these domains are.

In general, domains for STARKs consist of successive powers of primitive roots of unity. Specifically:

<p align="center">
1, ω, ω<sup>2</sup>, ω<sup>3</sup>, . . . , ω<sup>n-1</sup>
</p>

where *ω* is the *n*-th primitive root of unity. You can also think of *n* as the size of the domain and of *ω* as the domain's generator.

There are 3 domains with which we'll be working:

1. Domain of the trace table or *D<sub>trace</sub>* generated by *ω<sub>trace</sub>*. The size of this domain is equal to the length of the execution trace, and it is the smallest domain out of the three.
2. Constraint evaluation domain or *D<sub>ev</sub>* generated by *ω<sub>ev</sub>*. This domain is bigger than the trace domain by a factor of `MAX_CONSTRAINT_DEGREE`. Currently, `MAX_CONSTRAINT_DEGREE` is 8, so the constraint evaluation domain is 8 times bigger than the trace domain.
3. Low degree extension domain or *D<sub>lde</sub>* generated by *ω<sub>lde</sub>*. This domain is bigger than the trace domain by they `extension_factor` parameter. `extension_factor` must be at least 16 (but may be significantly bigger) - so, LDE domain is the biggest one of the three.

### 1. Extend execution trace

We can think of register traces in the execution trace table as evaluations of trace polynomials *T<sub>i</sub>(x)*. Thus, each row in the trace table can be written as:

<p align="center">
T<sub>0</sub>(ω<sup>i</sup><sub>trace</sub>), T<sub>1</sub>(ω<sup>i</sup><sub>trace</sub>), T<sub>2</sub>(ω<sup>i</sup><sub>trace</sub>), . . . T<sub>k</sub>(ω<sup>i</sup><sub>trace</sub>)
</p>

where, *k* is the number of registers, and *i* is the index of the row (same as the step of the computation).

To extend the trace table, we need to evaluate these polynomials over a larger domain. But since the trace table consists of polynomial evaluations, we first need to interpolate each register trace into a polynomial. We do this by running inverse FFT.

Then, trace polynomials are evaluated over *D<sub>lde</sub>* to generate the extended trace table (this is done by running regular FFT). Each row in the extended trace table can be written as:

<p align="center">
T<sub>0</sub>(ω<sup>i</sup><sub>lde</sub>), T<sub>1</sub>(ω<sup>i</sup><sub>lde</sub>), T<sub>2</sub>(ω<sup>i</sup><sub>lde</sub>), . . . T<sub>k</sub>(ω<sup>i</sup><sub>lde</sub>)
</p>

A couple of things to note:
1. The degree of trace polynomials is one less than trace length, or *deg(T<sub>i</sub>(x)) = |D<sub>trace</sub>| - 1*.
2. This is the most computationally intensive part of proof generation. Depending on the `extension_factor` used, it can take up between 40% to 65% of proof generation time (assuming single-threaded execution).

### 2. Build trace Merkle tree

After the execution trace table has been extended, we build a Merkle tree from the extended register traces. Leaves in the resulting tree will have the following form:

<p align="center">
Leaf<sub>i</sub> = (T<sub>0</sub>(ω<sup>i</sup><sub>lde</sub>), T<sub>1</sub>(ω<sup>i</sup><sub>lde</sub>), T<sub>2</sub>(ω<sup>i</sup><sub>lde</sub>), . . . T<sub>k</sub>(ω<sup>i</sup><sub>lde</sub>))
</p>

This step takes up about 10% of proof generation time.

### 3. Evaluate constraints
The next step is to evaluate constraints. The actual constraint definitions are described [here](constraints). Our eventual goal is to combine all constraints into a single *constraint polynomial*. We do this by computing a random linear combination of all constraints like so:

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large C(x) = \sum_i (\k_{2i} \cdot C_i(x) %2B \k_{2i%2B1} \cdot C_i(x) \cdot x^{d_i})">
</p>

where:
* *x = ω<sup>j</sup><sub>ev</sub>* for all *j* in the constraint evaluation domain.
* *C<sub>0</sub> ... C<sub>i</sub>* are the individual constraint evaluation functions.
* *k<sub>0</sub> ... k<sub>2i+1</sub>* are the coefficients for the random linear combination. These coefficients are derived using PRNG seeded with the root of the trace Merkle tree we built in the previous step.
* *d<sub>0</sub> ... d<sub>i</sub>* are the adjustment degrees needed to guarantee that constraint degrees are enforced exactly. Adjustment degrees are calculated as: *d<sub>i</sub> = [target degree] - deg(C<sub>i</sub>(x))*.

However, in this step, we don't compute the full constraint polynomial. Instead, we compute linear combinations of constraint numerators only. In the next step, we'll divide these linear combinations by their respective denominators. This allows us to minimize the number of divisions (which are expensive) and also reduces the amount of RAM needed to hold all constraint evaluations. Since our constraints can have 3 possible denominators, we'll still need to keep track of 3 separate linear combinations but that's much better than keeping track of 30+ individual constraint evaluations.

The 3 combinations we need to keep track of are:

1. Combination of transition constraints. The denominator for this combination is *(x<sup>n</sup> - 1) / (x - ω<sub>trace</sub><sup>(n-1)</sup>)*.
2. Combination of boundary constraints at the first step. The denominator for this combination is *(x - 1)*.
3. Combination of boundary constraints at the last step. The denominator for this combination is *(x - ω<sub>trace</sub><sup>(n-1)</sup>)*.

Because the denominators above have different degrees, *target degrees* for the linear combinations will be different. Specifically:
* Target degree for transition constraints will be *|D<sub>ev</sub>| - 1*.
* Target degree for boundary constraints will be *|D<sub>ev</sub>| - |D<sub>trace</sub>| + 1*

This way, when linear combinations are divided by their respective denominator, their degrees will align, and the degree for the final *constraint polynomial* will be:

<p align="center">
deg(C(x)) = |D<sub>ev</sub>| - |D<sub>trace</sub>|
</p>

For example, if our execution trace is 16 steps long:
* Transition constraint combination degree will be `16 * 8 - 1 = 127`.
* Boundary constraint combination degree will be `16 * 8 - 16 + 1 = 113`.
* Once the denominators are divided out, the final degree of the *constraint polynomial* will be `112`.

### 4. Convert constraint evaluations into a single polynomial
After constraints have been evaluated and combined into the 3 linear combinations, we do the following:
1. Interpolate each combination of constraint evaluation into a polynomial,
2. Divide out denominators from their respective polynomials,
3. Add the resulting polynomials together into the *constraint polynomial C(x)*.

### 5. Build Merkle tree from constraint polynomial evaluations
Once the *constraint polynomial* has been constructed, we evaluate it over the LDE domain and put the resulting values into a Merkle tree.

Since our values are 64 bits, but Merkle tree leaves are 256 bits, we put 4 consecutive evaluations into a single leaf like so:

<p align="center">
Leaf<sub>i</sub> = (C(x<sub>4i</sub>), C(x<sub>4i+1</sub>), C(x<sub>4i+2</sub>), C(x<sub>4i + 3</sub>))
</p>

*x<sub>i</sub> = ω<sup>i</sup><sub>lde</sub>* for all *i* in the low degree extension domain.

### 6. Build and evaluate deep composition polynomial
Next, we use the root of the tree constructed in the previous step to seed a new PRNG. We then use this PRNG to:

1. Draw a point *z* from the entire field,
2. Draw a set of coefficients for the random linear combination of constraint and trace polynomials.

This new random linear combination is called a *deep composition polynomial P(x)*. The degree of this polynomial will be one less than the degree of the constraint polynomial, or *deg(P(x)) = |D<sub>ev</sub>| - |D<sub>trace</sub>| - 1*.

Deep composition polynomial is constructed as folllows:

First, we compute *T<sub>i</sub>(z)* and *T<sub>i</sub>(z * ω<sub>trace</sub>)*, and divide these points out of trace polynomials like so:

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large T^'_i(x) = \frac{T_i(x) - T_i(z)}{x - z}">
</p>

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large T^''_i(x) = \frac{T_i(x) - T_i(z \cdot \omega_{trace})}{x - z \cdot \omega_{trace}}">
</p>

Then, we compute a random linear combination of the resulting polynomials as:

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large T(x) = \sum_i (\k_{2i} \cdot T^'_i(x) %2B \k_{2i%2B1} \cdot T^''_i(x))">
</p>

where *k<sub>0</sub> ... k<sub>2i+1</sub>* are the coefficients for the random linear combination.

Next, we raise the degree of the combined trace polynomials to make sure it matches the degree of the deep composition polynomial:

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large T^'(x) = \alpha \cdot T(x) %2B \beta \cdot T(x) \cdot x^d">
</p>

where:
* *α* and *β* are pseudo-random coefficients,
* *d* is the adjustment degree which is equal to *|D<sub>ev</sub>| - 2 * |D<sub>trace</sub>| + 1*.

Then we divide *z* point out of the constraint polynomial like so:

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large C^'(x) = \frac{C(x) - C(z)}{x - z}">
</p>

Finally, we combine this resulted deep constraint polynomial with the deep trace polynomial:

<p align="center">
<img src="https://render.githubusercontent.com/render/math?math=\large P(x) = T^'(x) %2B \gamma \cdot C^'(x)">
</p>

where, *γ* is yet another pseudo-random coefficient.

### 7. Compute FRI layers for the composition polynomial
TODO

### 8. Determine query positions
TODO

### 9. Build proof object
TODO

## Proof verification

### 1. Verify deep point evaluation
TODO

### 2. Verify proof of work and determine query positions
TODO

### 3. Verify trace and constraint Merkle proofs
TODO

### 4. Compute composition values
TODO

### 5. Verify low-degree proof
TODO